{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " “If you talk to a man in a language he understands, that goes to his head. If you talk to him in his own language, that goes to his heart.” – Nelson Mandela The skills of translation are becoming ever more important and desirable. Today’s multicultural and multilingual society demands effective, efficient, and empathetic communication between languages and cultures. That’s important for various reasons. i) Not Everybody Speaks English(Global language). ii) It Enables A Global Economy. iii) The Spread of Information and Ideas.\n",
    "\n",
    "Problem statement: The objective is to convert a Engish sentence to its Hindi counterpart using a Neural Machine Translation (NMT) system. The goal is to build a model with the help of neural networks, using python (precisely Tensorflow, keras), which translates the text into desired language. But, for this model to build, we need good size of the pre-translated data and then data should be prepared for the further process of building the model.\n",
    "\n",
    "Background : \"Machine Translation\" is generally known as MT (abbreviation), and it deals with the investigation of the use of software to translate text or speech from one language to another. i) Machine Translation is not a new idea, it was proposed few decades before, more precisely around 1949 in Warren weaver's Memorandum on Translation. ii) It is also said that this idea of universal language with equivalent idea in different tongues sharing one symbol is proposed by Rene Descartes in 1629. iii) From 1949 on wards there is a long list of researchers contributed to this idea in different ways and it is materialized in 21st century through the advancement of modern scientific computation. Human translation can be explained as decoding the meaning of the text from the source language and re-encoding the meaning into the target language.As this process is concerned, one should know the basic rules of both the languages (source language and target language), precisely the {Grammar}. This suggests that it involves a lot of human intuitions. To carry out this using machine (computationally) is a big challenge. So, for making this possible, it cannot be done automatocally, a kind of human aid is needed. So, the different approaches have evolved with the time to attain the needed accuracy. There are some of the approaches are mentioned below 1) Rule-Based machine translation 2) Statistical machine translation 3) Example based machine translation 4) Hybrid machine translation 5) Neural machine translation\n",
    "\n",
    "dataset explanation: The data taken is for English to French (fra.txt) , it constitutes of 1044268 sentences. The sentences are split into words and tokenized and then used for further process.\n",
    "\n",
    "Overall approach and major steps: Implementation of Sequence-to-Sequence (Seq2Seq) Modeling in Python using Keras. Major steps to follow: 1) Import the Required Libraries 2) Read the Data into our IDE 3) Text Cleaning 4) Text to Sequence Conversion 5) Model Building\n",
    "\n",
    "The dependent packages: 1) Tensorflow 2) keras 3) string 4) re 5) numpy 6) pandas 7) matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a text file (.txt) of English-French sentence pairs. First, we will read the file using the function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll then split these pairs into English sentences and French sentences respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these functions to read the text into an array in our desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"fra.txt\")\n",
    "fra_eng = to_lines(data)\n",
    "fra_eng = array(fra_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first take a look at our data. This will help us decide which pre-processing steps to adopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Va !'],\n",
       "       ['Hi.', 'Salut !'],\n",
       "       ['Run!', 'Cours\\u202f!'],\n",
       "       ...,\n",
       "       ['Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.',\n",
       "        \"Puisqu'il y a de multiples sites web sur chaque sujet, je clique d'habitude sur le bouton retour arrière lorsque j'atterris sur n'importe quelle page qui contient des publicités surgissantes. Je me rends juste sur la prochaine page proposée par Google et espère tomber sur quelque chose de moins irritant.\"],\n",
       "       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n",
       "        \"Si quelqu'un qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif, cela veut dire qu'il a probablement remarqué quelque chose à propos de votre élocution qui l'a fait prendre conscience que vous n'êtes pas un locuteur natif. En d'autres termes, vous ne parlez pas vraiment comme un locuteur natif.\"],\n",
       "       ['It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.',\n",
       "        \"Il est peut-être impossible d'obtenir un Corpus complètement dénué de fautes, étant donnée la nature de ce type d'entreprise collaborative. Cependant, si nous encourageons les membres à produire des phrases dans leurs propres langues plutôt que d'expérimenter dans les langues qu'ils apprennent, nous pourrions être en mesure de réduire les erreurs.\"]],\n",
       "      dtype='<U349')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160872"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fra_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual data contains over 160872 sentence-pairs. However, we will use full data. You can change this number as per your system’s computation power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_eng = fra_eng[:160872,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get rid of the punctuation marks and then convert all the text to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Va '],\n",
       "       ['Hi', 'Salut '],\n",
       "       ['Run', 'Cours\\u202f'],\n",
       "       ...,\n",
       "       ['Since there are usually multiple websites on any given topic I usually just click the back button when I arrive on any webpage that has popup advertising I just go to the next page found by Google and hope for something less irritating',\n",
       "        'Puisquil y a de multiples sites web sur chaque sujet je clique dhabitude sur le bouton retour arrière lorsque jatterris sur nimporte quelle page qui contient des publicités surgissantes Je me rends juste sur la prochaine page proposée par Google et espère tomber sur quelque chose de moins irritant'],\n",
       "       ['If someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker In other words you dont really sound like a native speaker',\n",
       "        'Si quelquun qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif cela veut dire quil a probablement remarqué quelque chose à propos de votre élocution qui la fait prendre conscience que vous nêtes pas un locuteur natif En dautres termes vous ne parlez pas vraiment comme un locuteur natif'],\n",
       "       ['It may be impossible to get a completely errorfree corpus due to the nature of this kind of collaborative effort However if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning we might be able to minimize errors',\n",
       "        'Il est peutêtre impossible dobtenir un Corpus complètement dénué de fautes étant donnée la nature de ce type dentreprise collaborative Cependant si nous encourageons les membres à produire des phrases dans leurs propres langues plutôt que dexpérimenter dans les langues quils apprennent nous pourrions être en mesure de réduire les erreurs']],\n",
       "      dtype='<U349')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "fra_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fra_eng[:,0]]\n",
    "fra_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fra_eng[:,1]]\n",
    "\n",
    "fra_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 'va '],\n",
       "       ['hi', 'salut '],\n",
       "       ['run', 'cours\\u202f'],\n",
       "       ...,\n",
       "       ['since there are usually multiple websites on any given topic i usually just click the back button when i arrive on any webpage that has popup advertising i just go to the next page found by google and hope for something less irritating',\n",
       "        'puisquil y a de multiples sites web sur chaque sujet je clique dhabitude sur le bouton retour arrière lorsque jatterris sur nimporte quelle page qui contient des publicités surgissantes je me rends juste sur la prochaine page proposée par google et espère tomber sur quelque chose de moins irritant'],\n",
       "       ['if someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker in other words you dont really sound like a native speaker',\n",
       "        'si quelquun qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif cela veut dire quil a probablement remarqué quelque chose à propos de votre élocution qui la fait prendre conscience que vous nêtes pas un locuteur natif en dautres termes vous ne parlez pas vraiment comme un locuteur natif'],\n",
       "       ['it may be impossible to get a completely errorfree corpus due to the nature of this kind of collaborative effort however if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning we might be able to minimize errors',\n",
       "        'il est peutêtre impossible dobtenir un corpus complètement dénué de fautes étant donnée la nature de ce type dentreprise collaborative cependant si nous encourageons les membres à produire des phrases dans leurs propres langues plutôt que dexpérimenter dans les langues quils apprennent nous pourrions être en mesure de réduire les erreurs']],\n",
       "      dtype='<U349')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text to lowercase\n",
    "for i in range(len(fra_eng)):\n",
    "    fra_eng[i,0] = fra_eng[i,0].lower()\n",
    "    fra_eng[i,1] = fra_eng[i,1].lower()\n",
    "\n",
    "fra_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Seq2Seq model requires that we convert both the input and the output sentences into integer sequences of fixed length.\n",
    "\n",
    "But before we do that, let’s visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and French, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "fra_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in fra_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in fra_eng[:,1]:\n",
    "      fra_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'fra':fra_l})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'away']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_eng[115,0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fra_eng[115,0].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite intuitive – the maximum length of the French sentences is 15 and that of the English phrases is 15.\n",
    "\n",
    "Next, vectorize our text data by using Keras’s Tokenizer() class. \n",
    "It will turn our sentences into sequences of integers. \n",
    "We can then pad those sequences with zeros to make all the sequences of the same length.\n",
    "\n",
    "Note that we will prepare tokenizers for both the French and English sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "      tokenizer = Tokenizer()\n",
    "      tokenizer.fit_on_texts(lines)\n",
    "      return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 14347\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(fra_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 15\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french Vocabulary Size: 32113\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "fra_tokenizer = tokenization(fra_eng[:, 1])\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "\n",
    "fra_length =15\n",
    "print('french Vocabulary Size: %d' % fra_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block contains a function to prepare the sequences. \n",
    "It will also perform sequence padding to a maximum sentence length as mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data into train and test set for model training and evaluation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(fra_eng, test_size=0.1, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s time to encode the sentences. We will encode French sentences as the input sequences and English sentences as the target sequences. This has to be done for both the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(fra_tokenizer, fra_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data\n",
    "testX = encode_sequences(fra_tokenizer, fra_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll start off by defining our Seq2Seq model architecture:\n",
    "\n",
    "For the encoder, we will use an embedding layer and an LSTM layer For the decoder, we will use another LSTM layer followed by a dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "      model.add(LSTM(units))\n",
    "      model.add(RepeatVector(out_timesteps))\n",
    "      model.add(LSTM(units, return_sequences=True))\n",
    "      model.add(Dense(out_vocab, activation='softmax'))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the RMSprop optimizer in this model as it’s usually a good choice when working with recurrent neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model = define_model(fra_vocab_size, eng_vocab_size, fra_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we have used ‘sparse_categorical_crossentropy‘ as the loss function. This is because the function allows us to use the target sequence as is, instead of the one-hot encoded format. One-hot encoding the target sequences using such a huge vocabulary might consume our system’s entire memory.\n",
    "\n",
    "We are all set to start training our model!\n",
    "\n",
    "We will train it for 30 epochs and with a batch size of 512 with a validation split of 10%. 90% of the data will be used for training the model and the rest for evaluating it. You may change and play around with these hyperparameters.\n",
    "\n",
    "We will also use the ModelCheckpoint() function to save the model with the lowest validation loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 130305 samples, validate on 14479 samples\n",
      "Epoch 1/30\n",
      "130305/130305 [==============================] - 1594s 12ms/step - loss: 2.8369 - val_loss: 2.5074\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.50737, saving model to model.h1.06_apr_19\n",
      "Epoch 2/30\n",
      "130305/130305 [==============================] - 1581s 12ms/step - loss: 2.3979 - val_loss: 2.2816\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.50737 to 2.28162, saving model to model.h1.06_apr_19\n",
      "Epoch 3/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 2.1429 - val_loss: 2.0406\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.28162 to 2.04061, saving model to model.h1.06_apr_19\n",
      "Epoch 4/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 1.9156 - val_loss: 1.8708\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.04061 to 1.87082, saving model to model.h1.06_apr_19\n",
      "Epoch 5/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 1.7210 - val_loss: 1.6923\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.87082 to 1.69232, saving model to model.h1.06_apr_19\n",
      "Epoch 6/30\n",
      "130305/130305 [==============================] - 1573s 12ms/step - loss: 1.5518 - val_loss: 1.5951\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.69232 to 1.59513, saving model to model.h1.06_apr_19\n",
      "Epoch 7/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 1.4048 - val_loss: 1.4701\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.59513 to 1.47005, saving model to model.h1.06_apr_19\n",
      "Epoch 8/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 1.2795 - val_loss: 1.3906\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.47005 to 1.39058, saving model to model.h1.06_apr_19\n",
      "Epoch 9/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 1.1699 - val_loss: 1.3231\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.39058 to 1.32315, saving model to model.h1.06_apr_19\n",
      "Epoch 10/30\n",
      "130305/130305 [==============================] - 1573s 12ms/step - loss: 1.0738 - val_loss: 1.2722\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.32315 to 1.27222, saving model to model.h1.06_apr_19\n",
      "Epoch 11/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.9906 - val_loss: 1.2346\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.27222 to 1.23456, saving model to model.h1.06_apr_19\n",
      "Epoch 12/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.9153 - val_loss: 1.2189\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.23456 to 1.21889, saving model to model.h1.06_apr_19\n",
      "Epoch 13/30\n",
      "130305/130305 [==============================] - 1573s 12ms/step - loss: 0.8500 - val_loss: 1.1984\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.21889 to 1.19841, saving model to model.h1.06_apr_19\n",
      "Epoch 14/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.7892 - val_loss: 1.1859\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.19841 to 1.18594, saving model to model.h1.06_apr_19\n",
      "Epoch 15/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 0.7337 - val_loss: 1.1606\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.18594 to 1.16065, saving model to model.h1.06_apr_19\n",
      "Epoch 16/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 0.6802 - val_loss: 1.1690\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.16065\n",
      "Epoch 17/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.6334 - val_loss: 1.1791\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.16065\n",
      "Epoch 18/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.5909 - val_loss: 1.1671\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.16065\n",
      "Epoch 19/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.5513 - val_loss: 1.1661\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.16065\n",
      "Epoch 20/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 0.5137 - val_loss: 1.1634\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.16065\n",
      "Epoch 21/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.4786 - val_loss: 1.1712\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.16065\n",
      "Epoch 22/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 0.4461 - val_loss: 1.1728\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.16065\n",
      "Epoch 23/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 0.4163 - val_loss: 1.1881\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.16065\n",
      "Epoch 24/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.3877 - val_loss: 1.2011\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.16065\n",
      "Epoch 25/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.3626 - val_loss: 1.2044\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.16065\n",
      "Epoch 26/30\n",
      "130305/130305 [==============================] - 1574s 12ms/step - loss: 0.3376 - val_loss: 1.2107\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.16065\n",
      "Epoch 27/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 0.3154 - val_loss: 1.2215\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.16065\n",
      "Epoch 28/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 0.2949 - val_loss: 1.2317\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.16065\n",
      "Epoch 29/30\n",
      "130305/130305 [==============================] - 1572s 12ms/step - loss: 0.2754 - val_loss: 1.2609\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.16065\n",
      "Epoch 30/30\n",
      "130305/130305 [==============================] - 1571s 12ms/step - loss: 0.2586 - val_loss: 1.2589\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.16065\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.06_apr_19'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.1,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s compare the training loss and the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above plot, the validation loss stopped decreasing after 10 epochs.\n",
    "\n",
    "Finally, we can load the saved model and make predictions on the unseen data – testY.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h1.06_apr_19')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions are sequences of integers. We need to convert these integers to their corresponding words. Let’s define a function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert predictions into text (English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "       temp = []\n",
    "       for j in range(len(i)):\n",
    "            t = get_word(i[j], eng_tokenizer)\n",
    "            if j > 0:\n",
    "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                     temp.append('')\n",
    "                else:\n",
    "                     temp.append(t)\n",
    "            else:\n",
    "                   if(t == None):\n",
    "                          temp.append('')\n",
    "                   else:\n",
    "                          temp.append(t) \n",
    "\n",
    "       preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can randomly print some actual vs predicted instances to see how our model performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>they painted the fence green</td>\n",
       "      <td>they painted the fence green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11766</th>\n",
       "      <td>why did you paint this wall black</td>\n",
       "      <td>why did you paint the wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>mary is not wearing a bra</td>\n",
       "      <td>mary is wears like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>she was breathing hard</td>\n",
       "      <td>she is with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>im not done with you yet</td>\n",
       "      <td>im not done with you yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12372</th>\n",
       "      <td>tom lost</td>\n",
       "      <td>tom lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8855</th>\n",
       "      <td>i regret doing that</td>\n",
       "      <td>i regret that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>what does your son do</td>\n",
       "      <td>what made your you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>everyones out</td>\n",
       "      <td>everyones is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>you could get arrested for that</td>\n",
       "      <td>the police could stop this that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13601</th>\n",
       "      <td>my mother has made me what i am today</td>\n",
       "      <td>my mother made  what  was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>i caught them in the act</td>\n",
       "      <td>i caught up in the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6241</th>\n",
       "      <td>are you telling me youre not involved</td>\n",
       "      <td>are you telling me youre not involved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9076</th>\n",
       "      <td>you werent serious were you</td>\n",
       "      <td>you werent serious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>youre supposed to help your friends when theyre in trouble</td>\n",
       "      <td>you supposed to help friends   theyre in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           actual  \\\n",
       "8379                                 they painted the fence green   \n",
       "11766                           why did you paint this wall black   \n",
       "10957                                   mary is not wearing a bra   \n",
       "8398                                       she was breathing hard   \n",
       "1826                                     im not done with you yet   \n",
       "12372                                                    tom lost   \n",
       "8855                                          i regret doing that   \n",
       "9292                                        what does your son do   \n",
       "11998                                               everyones out   \n",
       "304                               you could get arrested for that   \n",
       "13601                       my mother has made me what i am today   \n",
       "984                                      i caught them in the act   \n",
       "6241                        are you telling me youre not involved   \n",
       "9076                                  you werent serious were you   \n",
       "787    youre supposed to help your friends when theyre in trouble   \n",
       "\n",
       "                                            predicted  \n",
       "8379           they painted the fence green            \n",
       "11766             why did you paint the wall           \n",
       "10957                   mary is wears like             \n",
       "8398                          she is with              \n",
       "1826                im not done with you yet           \n",
       "12372                           tom lost               \n",
       "8855                        i regret that              \n",
       "9292                    what made your you             \n",
       "11998                       everyones is               \n",
       "304          the police could stop this that           \n",
       "13601               my mother made  what  was          \n",
       "984                      i caught up in the            \n",
       "6241    are you telling me youre not involved          \n",
       "9076                   you werent serious              \n",
       "787    you supposed to help friends   theyre in        "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Seq2Seq model does a decent job. But there are several instances where it misses out on understanding the key words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
